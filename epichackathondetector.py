# -*- coding: utf-8 -*-
"""epichackathondetector.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1tr1IP8ivOu8q9wTJDO2sXBY9jzQyEAuG
"""

import numpy as np
from datetime import datetime 
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import DataLoader
from torchvision import datasets, transforms
import matplotlib.pyplot as plt
import pandas as pd
from skimage import io, transform
import matplotlib.pyplot as plt
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms, utils
# Ignore warnings
import warnings
warnings.filterwarnings("ignore")
  
plt.ion()   # interactive mode
# check device
DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'

"""This will be very epic and poggers"""



from torch.utils.data import Dataset
import pandas as pd
import os
import torchvision
from PIL import Image
import torch

class recycleDataset(Dataset):
    def __init__(self, root_dir, annotation_file, transform=None):
        self.root_dir = root_dir
        self.annotations = pd.read_csv(annotation_file)
        self.transform = transform

    def __len__(self):
        return len(self.annotations)

    def __getitem__(self, index):
        img_id = self.annotations.iloc[index, 0]
        img = Image.open(os.path.join(self.root_dir, img_id)).convert("RGB")
        y_label = torch.tensor(float(self.annotations.iloc[index, 1]))

        if self.transform is not None:
            img = self.transform(img)

        return (img, y_label)

import pandas as pd
import os
import torch

device = ("cuda" if torch.cuda.is_available() else "cpu")

train_df = pd.DataFrame(columns=["img_path","label"])
train_df["img_path"] = os.listdir("C:/Users/msajid/Desktop/pogmachinelearning/RecyclingImages")
for idx, i in enumerate(os.listdir("C:/Users/msajid/Desktop/pogmachinelearning/RecyclingImages")):
    if "pep" in i:
        train_df["label"][idx] = 0
    if "pap" in i:
        train_df["label"][idx] = 1
train_df.to_csv(r'C:/Users/msajid/Desktop/pogmachinelearning/train_csv.csv', index = False, header=True)

import torch.nn as nn
import torchvision.models as models

class CNN(nn.Module):
    def __init__(self, train_CNN=False, num_classes=1):
        super(CNN, self).__init__()
        self.train_CNN = train_CNN
        self.inception = models.inception_v3(pretrained=True, aux_logits=False)
        self.inception.fc = nn.Linear(self.inception.fc.in_features, num_classes)
        self.relu = nn.ReLU()
        self.dropout = nn.Dropout(0.5)
        self.sigmoid = nn.Sigmoid()

    def forward(self, images):
        features = self.inception(images)
        return self.sigmoid(self.dropout(self.relu(features))).squeeze(1)

import torch
import torch.nn as nn
from torch.utils.data import DataLoader
import torchvision.transforms as transforms

transform = transforms.Compose(
        [
            transforms.Resize((1000, 1000)),
            transforms.RandomCrop((950, 950)),
            transforms.ToTensor(),
            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),
        ]
    )
# parameters
# parameters
num_epochs = 10
learning_rate = 0.00001
train_CNN = False
batch_size = 1
shuffle = True
pin_memory = True
num_workers = 1

dataset = recycleDataset("C:/Users/msajid/Desktop/pogmachinelearning/RecyclingImages","C:/Users/msajid/Desktop/pogmachinelearning/train_csv.csv",transform=transform)
train_set, validation_set = torch.utils.data.random_split(dataset,[30,30])
train_loader = DataLoader(dataset=train_set, shuffle=shuffle, batch_size=batch_size,num_workers=num_workers,pin_memory=pin_memory)
validation_loader = DataLoader(dataset=validation_set, shuffle=shuffle, batch_size=batch_size,num_workers=num_workers, pin_memory=pin_memory)

from tqdm import tqdm
model = CNN().to(device)

criterion = nn.BCELoss()
optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)

for name, param in model.inception.named_parameters():
    if "fc.weight" in name or "fc.bias" in name:
        param.requires_grad = True
    else:
        param.requires_grad = train_CNN
def check_accuracy(loader, model):
    if loader == train_loader:
        print("Checking accuracy on training data")
    else:
        print("Checking accuracy on validation data")

    num_correct = 0
    num_samples = 0
    model.eval()

    with torch.no_grad():
        for x, y in loader:
            x = x.to(device=device)
            y = y.to(device=device)
            scores = model(x)
            predictions = torch.tensor([1.0 if i >= 0.5 else 0.0 for i in scores]).to(device)
            num_correct += (predictions == y).sum()
            num_samples += predictions.size(0)
    return f"{float(num_correct)/float(num_samples)*100:.2f}"
    model.train()
def train():
    model.train()
    for epoch in range(num_epochs):
        loop = tqdm(train_loader, total = len(train_loader), leave = True)
        if epoch % 2 == 0:
            loop.set_postfix(val_acc = check_accuracy(validation_loader, model))
        for imgs, labels in loop:
            imgs = imgs.to(device)
            labels = labels.to(device)
            outputs = model(imgs)
            loss = criterion(outputs, labels)
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            loop.set_description(f"Epoch [{epoch}/{num_epochs}]")
            loop.set_postfix(loss = loss.item())
if __name__ == "__main__":
    train()
torch.save(model,"C:/Users/msajid/Desktop/pogmachinelearning/test")
#img = Image.open("/content/drive/MyDrive/Colab Notebooks/pepe2021-03-07_0228.jpg").convert("RGB")
#y_label = torch.tensor(float(self.annotations.iloc[index, 1]))
'''
transform = transforms.Compose(
        [
            transforms.Resize((1000, 1000)),
            transforms.RandomCrop((950, 950)),
            transforms.ToTensor(),
            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),
        ]
    )
img = transform(img)
label=0
y_label = torch.tensor(float(label))
img = img.unsqueeze(0)
with torch.no_grad():
  model.eval()
  img = img.to(device=device)
  y = y_label.to(device=device)
  pred = model(img)
  print(pred)
  predictions = torch.tensor([1.0 if i >= 0.52 else 0.0 for i in pred]).to(device)
  print(predictions)
'''
